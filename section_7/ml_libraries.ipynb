{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "ml_libraries.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyNRwbedS9fnG8lJckvbuwlx",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "pycharm-d262f193",
   "language": "python",
   "display_name": "PyCharm (udemy_python_zero_ai)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yukinaga/minnano_ai/blob/master/section_7/ml_libraries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gpLdgYqPxp5",
    "colab_type": "text"
   },
   "source": [
    "# 機械学習ライブラリ\n",
    "機械学習ライブラリ、KerasとPyTorchのコードを紹介します。  \n",
    "今回はコードの詳しい解説は行いませんが、実装の大まかな流れを把握しましょう。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WguhKCRZdgV_",
    "colab_type": "text"
   },
   "source": [
    "## ● Kerasのコード\n",
    "以下のコードは、Kerasによるシンプルなニューラルネットワークの実装です。  \n",
    "Irisの各花を、SetosaとVersicolorに分類します。  \n",
    "以下のコードでは、`Sequential`でモデルを作り、層や活性化関数を追加しています。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7uN-2AkcPCa5",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_data = iris.data\n",
    "sl_data = iris_data[:100, 0] # SetosaとVersicolor、Sepal length\n",
    "sw_data = iris_data[:100, 1] # SetosaとVersicolor、Sepal width\n",
    "\n",
    "# 平均値を0に\n",
    "sl_ave = np.average(sl_data)  # 平均値\n",
    "sl_data -= sl_ave  # 平均値を引く\n",
    "sw_ave = np.average(sw_data)\n",
    "sw_data -= sw_ave\n",
    "\n",
    "# 入力をリストに格納\n",
    "input_data = []\n",
    "correct_data = []\n",
    "for i in range(100):\n",
    "    input_data.append([sl_data[i], sw_data[i]])\n",
    "    correct_data.append([iris.target[i]])\n",
    "\n",
    "# 訓練データとテストデータに分割\n",
    "input_data = np.array(input_data)  # NumPyの配列に変換\n",
    "correct_data = np.array(correct_data)\n",
    "x_train, x_test, t_train, t_test = train_test_split(input_data, correct_data)\n",
    "\n",
    "# ------ ここからKerasのコード ------\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=2)) # 入力:2、中間層のニューロン数:2\n",
    "model.add(Activation(\"sigmoid\")) # シグモイド関数\n",
    "model.add(Dense(1)) # 出力層のニューロン数:1\n",
    "model.add(Activation(\"sigmoid\")) # シグモイド関数\n",
    "model.compile(optimizer=SGD(lr=0.3), loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, t_train, epochs=32, batch_size=1)  # 訓練\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, t_test)\n",
    "print(\"正解率: \" + str(accuracy*100) + \"%\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-gMuglhk1k9",
    "colab_type": "text"
   },
   "source": [
    "## ● PyTorchのコード\n",
    "以下のコードは、PyTorchよるシンプルなニューラルネットワークの実装です。  \n",
    "Irisの各花を、SetosaとVersicolorに分類します。  \n",
    "以下のコードでは、Kerasと同様に`Sequential`でモデルを作り、層や活性化関数を並べています。  \n",
    "PyTorchでは、入力や正解をTensor形式のデータに変換する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "djZH-6V39iq8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_data = iris.data\n",
    "sl_data = iris_data[:100, 0] # SetosaとVersicolor、Sepal length\n",
    "sw_data = iris_data[:100, 1] # SetosaとVersicolor、Sepal width\n",
    "\n",
    "# 平均値を0に\n",
    "sl_ave = np.average(sl_data)  # 平均値\n",
    "sl_data -= sl_ave  # 平均値を引く\n",
    "sw_ave = np.average(sw_data)\n",
    "sw_data -= sw_ave\n",
    "\n",
    "# 入力をリストに格納\n",
    "input_data = []\n",
    "correct_data = []\n",
    "for i in range(100):\n",
    "    input_data.append([sl_data[i], sw_data[i]])\n",
    "    correct_data.append([iris.target[i]])\n",
    "\n",
    "# 訓練データとテストデータに分割\n",
    "input_data = np.array(input_data)  # NumPyの配列に変換\n",
    "correct_data = np.array(correct_data)\n",
    "x_train, x_test, t_train, t_test = train_test_split(input_data, correct_data)\n",
    "\n",
    "# ------ ここからPyTorchのコード ------\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "# Tensorに変換\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "t_train = torch.tensor(t_train, dtype=torch.float32) \n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "t_test = torch.tensor(t_test, dtype=torch.float32) \n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(2, 2), # 入力:2、中間層のニューロン数:2\n",
    "    nn.Sigmoid(), # シグモイド関数\n",
    "    nn.Linear(2, 1), # 出力層のニューロン数:1\n",
    "    nn.Sigmoid() # シグモイド関数\n",
    ")\n",
    "\n",
    "loss_fnc = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.3)\n",
    "\n",
    "# 1000エポック学習\n",
    "for i in range(1000):\n",
    "\n",
    "    # 勾配を0に\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 順伝播\n",
    "    y_train = net(x_train)\n",
    "    y_test = net(x_test)\n",
    "    \n",
    "    # 誤差を求める\n",
    "    loss_train = loss_fnc(y_train, t_train)\n",
    "    loss_test = loss_fnc(y_test, t_test)\n",
    "\n",
    "    # 逆伝播（勾配を求める）\n",
    "    loss_train.backward()\n",
    "    \n",
    "    # パラメータの更新\n",
    "    optimizer.step()\n",
    "\n",
    "    if i%100 == 0:\n",
    "        print(\"Epoch:\", i, \"Loss_Train:\", loss_train.item(), \"Loss_Test:\", loss_test.item())\n",
    "\n",
    "y_test = net(x_test)\n",
    "count = ((y_test.detach().numpy()>0.5) == (t_test.detach().numpy()==1.0)).sum().item()\n",
    "print(\"正解率: \" + str(count/len(y_test)*100) + \"%\")"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss_Train: 0.2594730257987976 Loss_Test: 0.25115740299224854\n",
      "Epoch: 100 Loss_Train: 0.22102932631969452 Loss_Test: 0.24556970596313477\n",
      "Epoch: 200 Loss_Train: 0.15973171591758728 Loss_Test: 0.18285588920116425\n",
      "Epoch: 300 Loss_Train: 0.09611750394105911 Loss_Test: 0.11673138290643692\n",
      "Epoch: 400 Loss_Train: 0.059146951884031296 Loss_Test: 0.07832591235637665\n",
      "Epoch: 500 Loss_Train: 0.04001173377037048 Loss_Test: 0.05797707661986351\n",
      "Epoch: 600 Loss_Train: 0.029384208843111992 Loss_Test: 0.04636969417333603\n",
      "Epoch: 700 Loss_Train: 0.022904139012098312 Loss_Test: 0.03919101133942604\n",
      "Epoch: 800 Loss_Train: 0.01863018423318863 Loss_Test: 0.03447197005152702\n",
      "Epoch: 900 Loss_Train: 0.015633489936590195 Loss_Test: 0.031232118606567383\n",
      "正解率: 96.0%\n"
     ]
    }
   ]
  }
 ]
}